{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2259e72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.0001 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content='You are a helpful assistant.', timestamp=datetime.datetime(2026, 2, 21, 1, 35, 52, 403601)), UserPromptPart(content='What is the weather today?', timestamp=datetime.datetime(2026, 2, 21, 1, 35, 52, 403606))]),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='search', args='weather today', tool_call_id='1')], usage=RequestUsage(), timestamp=datetime.datetime(2026, 2, 21, 1, 35, 52, 403608)),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='search', content='The weather today is sunny with a high of 25°C.', tool_call_id='1', timestamp=datetime.datetime(2026, 2, 21, 1, 35, 52, 403614))]),\n",
       " ModelResponse(parts=[TextPart(content='The weather today is sunny with a high of 25°C.')], usage=RequestUsage(), timestamp=datetime.datetime(2026, 2, 21, 1, 35, 52, 403617)),\n",
       " ModelRequest(parts=[UserPromptPart(content='Let me introduce my self, My name is Wang Huan and I am 32 years old, a middle age AI engineer living in the city of Beijing.', timestamp=datetime.datetime(2026, 2, 21, 1, 35, 52, 403621))])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent_runner import AgentRunner\n",
    "\n",
    "from events import (\n",
    "    AgentTextStream,\n",
    "    ToolCallsOutputStart,\n",
    "    ToolCallsOutput,\n",
    "    AgentHandoff,\n",
    "    ToolCallResult,\n",
    "    AgentTextOutput,\n",
    "    AgentResult,\n",
    "    EventType,\n",
    "    StructuredOutput\n",
    ")\n",
    "\n",
    "import time\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "from voice_agent_flow.llms import create_pydantic_azure_openai\n",
    "\n",
    "from pydantic_ai.messages import (\n",
    "    UserPromptPart, \n",
    "    TextPart, \n",
    "    ToolCallPart, \n",
    "    ToolReturnPart, \n",
    "    SystemPromptPart\n",
    ")\n",
    "\n",
    "from pydantic_ai import ModelRequest, ModelResponse\n",
    "from datetime import datetime\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class PydanticMessageAdaptor:\n",
    "\n",
    "    def user(\n",
    "        self,\n",
    "        content:str, \n",
    "        timestamp: datetime = None) -> ModelRequest:\n",
    "        \n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now()\n",
    "            \n",
    "        return ModelRequest(\n",
    "            parts = [\n",
    "                UserPromptPart(content=content, timestamp=timestamp)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def assistant(\n",
    "        self,\n",
    "        content:str,\n",
    "        timestamp = None) -> ModelResponse:\n",
    "        \n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now()\n",
    "        \n",
    "        return ModelResponse(\n",
    "            parts = [TextPart(content=content)],\n",
    "            timestamp=timestamp\n",
    "        )\n",
    "        \n",
    "    def tool_call(\n",
    "        self,\n",
    "        tool_name:str, \n",
    "        args: str, \n",
    "        tool_call_id:str = 'fake', \n",
    "        timestamp = None) -> ModelResponse:\n",
    "        \n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now()\n",
    "        \n",
    "        return ModelResponse(\n",
    "            parts = [ToolCallPart(\n",
    "                tool_name=tool_name, \n",
    "                args=args, \n",
    "                tool_call_id=tool_call_id)],\n",
    "            timestamp=timestamp\n",
    "        )\n",
    "        \n",
    "    def tool_return(\n",
    "        self,\n",
    "        tool_name:str, \n",
    "        content:str,\n",
    "        tool_call_id:str = 'fake', \n",
    "        timestamp = None) -> ModelResponse:\n",
    "        \n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now()\n",
    "            \n",
    "        return ModelRequest(\n",
    "            parts = [ToolReturnPart(\n",
    "                tool_name=tool_name, \n",
    "                content=content, \n",
    "                tool_call_id=tool_call_id, \n",
    "                timestamp=timestamp)]\n",
    "        )\n",
    "        \n",
    "    def system(\n",
    "        self, \n",
    "        content:str, \n",
    "        timestamp = None) -> ModelRequest:\n",
    "        \n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now()\n",
    "            \n",
    "        return ModelRequest(\n",
    "            parts = [\n",
    "                SystemPromptPart(content=content, timestamp=timestamp)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def auto(self, msg:dict):\n",
    "        \n",
    "        if 'timestamp' in msg:\n",
    "            timestamp = datetime.fromisoformat(msg['timestamp'])\n",
    "            \n",
    "        else:\n",
    "            timestamp = datetime.now()\n",
    "            \n",
    "        if msg['role'] == 'system':\n",
    "            return self.system(content=msg['content'], timestamp=timestamp)\n",
    "        \n",
    "        elif msg['role'] == 'user':\n",
    "            return self.user(content=msg['content'], timestamp=timestamp)\n",
    "        \n",
    "        elif msg['role'] == 'tool':\n",
    "            return self.tool_return(\n",
    "                tool_name=msg['tool_name'], \n",
    "                content=msg['content'],\n",
    "                tool_call_id=msg.get('tool_call_id', 'fake'),\n",
    "                timestamp=timestamp\n",
    "            )\n",
    "            \n",
    "        elif msg['role'] == 'assistant':\n",
    "            if \"content\" in msg:\n",
    "                return self.assistant(content=msg['content'], timestamp=timestamp)\n",
    "            \n",
    "            elif \"tool_name\" in msg:\n",
    "                return self.tool_call(\n",
    "                    tool_name=msg['tool_name'], \n",
    "                    args=msg.get('args', ''), \n",
    "                    tool_call_id=msg.get('tool_call_id', 'fake'), \n",
    "                    timestamp=timestamp\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid assistant message format: {msg}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown role: {msg['role']}\")\n",
    "    \n",
    "    def validate(self, message_history: list):\n",
    "        \n",
    "        history = [self.auto(msg) for msg in message_history]\n",
    "        \n",
    "        merged_history = []\n",
    "        for msg in history:\n",
    "            if not merged_history:\n",
    "                merged_history.append(msg)\n",
    "                \n",
    "            else:\n",
    "                last_msg = merged_history[-1]\n",
    "                if isinstance(last_msg, ModelRequest) and isinstance(msg, ModelRequest):\n",
    "                    last_msg.parts.extend(msg.parts)\n",
    "                    \n",
    "                elif isinstance(last_msg, ModelResponse) and isinstance(msg, ModelResponse):\n",
    "                    last_msg.parts.extend(msg.parts)\n",
    "                    \n",
    "                else:\n",
    "                    merged_history.append(msg)\n",
    "                    \n",
    "        return merged_history\n",
    "            \n",
    "    \n",
    "start = time.time()\n",
    "pmsg = PydanticMessageAdaptor()\n",
    "\n",
    "pmsg.tool_return('search', 'search result here')\n",
    "pmsg.assistant('This is a response from the assistant.')\n",
    "pmsg.user('What is the weather today?')\n",
    "pmsg.tool_call('search', 'weather today')\n",
    "pmsg.system(\"You are a helpful assistant.\")\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time taken: {end - start:.4f} seconds\")\n",
    "\n",
    "\n",
    "message_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather today?\"},\n",
    "    {\"role\": \"assistant\", \"tool_name\": \"search\", \"args\": \"weather today\", \"tool_call_id\": \"1\"},\n",
    "    {\"role\": \"tool\", \"tool_name\": \"search\", \"content\": \"The weather today is sunny with a high of 25°C.\", \"tool_call_id\": \"1\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The weather today is sunny with a high of 25°C.\"},\n",
    "    {'role': \"user\", \"content\": \"Let me introduce my self, My name is Wang Huan and I am 32 years old, a middle age AI engineer living in the city of Beijing.\"}\n",
    "]\n",
    "\n",
    "pmsg.validate(message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082508df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test tool call query ===\n",
      "\n",
      "=== Running query: What is the weather in New York City? ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://azure-m7byy3cl-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:root:呃, 稍等我想下啊。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚾️ New Event:\n",
      "AgentResult(event=ToolCallsOutputStart(status=None, message={'tool_name': 'weather_tool', 'args': '', 'tool_call_id': 'call_QjTaAVBOSRt87bZfDHhWWYLk', 'id': None, 'provider_details': None, 'part_kind': 'tool-call'}), event_type='ToolCallsOutputStart', finish_reason='', last_agent_name='')\n",
      "\n",
      "⚾️ New Event:\n",
      "AgentResult(event=ToolCallsOutput(status=None, message={'tool_name': 'weather_tool', 'args': '{\"location\":\"New York City\"}', 'tool_call_id': 'call_QjTaAVBOSRt87bZfDHhWWYLk', 'id': None, 'provider_details': None, 'part_kind': 'tool-call'}), event_type='ToolCallsOutput', finish_reason='', last_agent_name='')\n",
      "\n",
      "⚾️ New Event:\n",
      "AgentResult(event=ToolCallResult(status=None, message={'tool_name': 'weather_tool', 'content': 'The weather in New York City is snowing, the temperature will be below -5 degrees Celsius.', 'tool_call_id': 'call_QjTaAVBOSRt87bZfDHhWWYLk', 'metadata': None, 'timestamp': '2026-02-20T16:33:30.942121Z', 'part_kind': 'tool-return'}), event_type='ToolCallResult', finish_reason='', last_agent_name='')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://azure-m7byy3cl-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-03-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚾️ Agent starts to generate text:\n",
      "纽约现在正在下雪，气温在零下5度以下。建议你穿厚羽绒服、帽子、围巾和手套，注意保暖哦！如果需要外出，记得防滑，安全第一。\n",
      "\n",
      "=== Test name query ===\n",
      "\n",
      "=== Running query: My name is wanghuan, 32 years old. ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://azure-m7byy3cl-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:root:呃, 稍等我想下啊。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚾️ New Event:\n",
      "AgentResult(event=ToolCallsOutputStart(status=None, message={'tool_name': 'final_result', 'args': '', 'tool_call_id': 'call_Tf3rFfp7fS9EL6b9l1nYXtt6', 'id': None, 'provider_details': None, 'part_kind': 'tool-call'}), event_type='ToolCallsOutputStart', finish_reason='', last_agent_name='')\n",
      "\n",
      "⚾️ Found structured output:\n",
      "name='wanghuan' age=32\n",
      "\n",
      "⚾️ I want to transfer to the next step.\n"
     ]
    }
   ],
   "source": [
    "class Person(BaseModel):\n",
    "    name:str\n",
    "    age:int\n",
    "    \n",
    "    def transfer(self):\n",
    "        print(\"\\n⚾️ I want to transfer to the next step.\")\n",
    "    \n",
    "    \n",
    "def weather_tool(location: str, credential = \"3234980988908333498\") -> str:\n",
    "    \"\"\"Search the weather for a location.\"\"\"\n",
    "    return f\"The weather in {location} is snowing, the temperature will be below -5 degrees Celsius.\"\n",
    "\n",
    "tool_call_query = 'What is the weather in New York City?'\n",
    "name_query = \"My name is wanghuan, 32 years old.\"\n",
    "\n",
    "\n",
    "model = create_pydantic_azure_openai(model_name = \"gpt-4.1\")\n",
    "\n",
    "# this is the actual agent definition.\n",
    "agent = Agent(\n",
    "    model, \n",
    "    tools = [weather_tool],\n",
    "    instructions = (\n",
    "    \"You are a helpful assistant. you chat with users friendly.\"\n",
    "    \"When user asks questions about weather, do call the weather tool to get the weather information, and give suggestions on clothing based on the weather. \"\n",
    "    \"When user mentions any person with name and age, you extract the name and age, return a json object defined by `Person` schema.\"\n",
    "    \"Reply in Chinese.\"\n",
    "    \"\"),\n",
    "    output_type = str | Person)\n",
    "\n",
    "runner = AgentRunner(agent)\n",
    "\n",
    "async def run_one_turn(query):\n",
    "    print(f\"\\n=== Running query: {query} ===\")\n",
    "    no_text = True\n",
    "    \n",
    "    async for event in runner.run(query):\n",
    "        \n",
    "        # handle structured output events.\n",
    "        if not isinstance(event, AgentResult):\n",
    "            continue\n",
    "        \n",
    "        # add text stream to context / pending responses\n",
    "        if isinstance(event.event, AgentTextStream):\n",
    "            time.sleep(0.05)\n",
    "            if event.event.delta is None or event.event.delta == \"\":\n",
    "                continue\n",
    "            \n",
    "            if no_text:\n",
    "                print(\"\\n⚾️ Agent starts to generate text:\")\n",
    "            print(event.event.delta, end='', flush=True)\n",
    "            no_text = False\n",
    "            continue\n",
    "        \n",
    "        if isinstance(event.event, StructuredOutput):\n",
    "            print(\"\\n⚾️ Found structured output:\")\n",
    "            print(event.event.message)\n",
    "            if hasattr(event.event.message, 'transfer'):\n",
    "                event.event.message.transfer()\n",
    "        \n",
    "        # add tool history to memory\n",
    "        else:\n",
    "            print(\"\\n⚾️ New Event:\")\n",
    "            print(event)\n",
    "        \n",
    "print(\"\\n=== Test tool call query ===\")\n",
    "await run_one_turn(tool_call_query)\n",
    "\n",
    "print(\"\\n\\n=== Test name query ===\")\n",
    "await run_one_turn(name_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8d62d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
